name: Build FAA charts and upload to B2

on:
  workflow_dispatch:
    inputs:
      chart_args:
        description: 'Chartmaker args (e.g., area-single=12, full-single=0, area-all)'
        required: true
        default: 'area-single=12'
      bucket_prefix:
        description: 'Prefix inside the B2 bucket (e.g., charts/prod)'
        required: true
        default: 'charts/prod'

jobs:
  build:
    runs-on: ubuntu-latest

    # Use the prebuilt chartmaker image so Node, GDAL, etc. are ready.
    container:
      image: n129bz/chartmaker:latest
      options: >-
        --entrypoint /bin/bash

    env:
      # Backblaze B2 S3 credentials (from your repo secrets)
      AWS_ACCESS_KEY_ID: ${{ secrets.B2_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.B2_APPLICATION_KEY }}
      B2_ENDPOINT: ${{ secrets.B2_ENDPOINT }}     # e.g., https://s3.us-west-004.backblazeb2.com
      B2_BUCKET: ${{ secrets.B2_BUCKET_NAME }}
      # Cloudflare (optional)
      CF_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
      CF_ZONE_ID: ${{ secrets.CLOUDFLARE_ZONE_ID }}
      # Workflow inputs
      CHART_ARGS: ${{ github.event.inputs.chart_args }}
      BUCKET_PREFIX: ${{ github.event.inputs.bucket_prefix }}
      # Verbose command logging from chartmaker? (true/false)
      MAKE_VERBOSE: "false"

    steps:
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Show environment (debug)
        run: |
          set -euxo pipefail
          node -v
          gdalinfo --version || true
          echo "CHART_ARGS: $CHART_ARGS"
          echo "B2_BUCKET: $B2_BUCKET"
          echo "BUCKET_PREFIX: $BUCKET_PREFIX"
          echo "B2_ENDPOINT: $B2_ENDPOINT"

      # --- TEMP PATCH: guard an undefined 'dbf' in make.js (prevents your TypeError) ---
      - name: Patch chartmaker for dbf null-guard
        working-directory: /chartmaker
        run: |
          set -euxo pipefail
          # Only patch if the line exists and hasn't been patched already
          if grep -n 'dbf.length' make.js >/dev/null 2>&1; then
            sed -i 's/(dbf.length > 0 && fs.existsSync(dbf))/(dbf && dbf.length > 0 && fs.existsSync(dbf))/' make.js
          fi

      # Run chartmaker inside the image
      - name: Run chartmaker to build selected charts (container)
        working-directory: /chartmaker
        env:
          # Let chartmaker write DBs into its default folder (/chartmaker/public/charts)
          # You can change the default in settings.json if you want a different path.
          MAKE_VERBOSE: ${{ env.MAKE_VERBOSE }}
        run: |
          set -euxo pipefail

          # (Optional) show chosen settings for reproducibility
          node make -s || true

          # Build the selected chart(s) using command-line args
          # Examples:
          #   area-single=12     -> a single sectional area by index (0..52)
          #   area-all           -> all sectional areas
          #   full-single=0      -> "Sectional" full bundle
          #   full-single=7      -> "US_VFR_Wall_Planning"
          node make "$CHART_ARGS"

      - name: List generated databases (debug)
        run: |
          set -euxo pipefail
          find /chartmaker/public/charts -maxdepth 1 -type f -name '*.db' -printf "%f\n" || true

      - name: Install AWS CLI for B2 S3 uploads
        run: |
          set -euxo pipefail
          apt-get update
          apt-get install -y curl unzip groff less
          curl -sSL "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip -q awscliv2.zip
          ./aws/install --bin-dir /usr/local/bin --install-dir /usr/local/aws-cli || true
          aws --version

      - name: Upload to Backblaze B2 (S3 API)
        env:
          AWS_DEFAULT_REGION: us-west-004
        run: |
          set -euxo pipefail
          SRC_DIR="/chartmaker/public/charts"
          # Create a manifest and upload every .db produced
          shopt -s nullglob
          for f in "$SRC_DIR"/*.db; do
            base="$(basename "$f")"
            dest="s3://${B2_BUCKET}/${BUCKET_PREFIX}/${base}"
            echo "Uploading $f -> $dest"
            aws s3 cp "$f" "$dest" --endpoint-url "${B2_ENDPOINT}" --only-show-errors
          done

      - name: (Optional) Purge Cloudflare cache
        if: ${{ env.CF_API_TOKEN && env.CF_ZONE_ID }}
        run: |
          set -euxo pipefail
          # Purge whole zone cache so the CDN serves fresh db URLs
          curl -sS -X POST "https://api.cloudflare.com/client/v4/zones/${CF_ZONE_ID}/purge_cache" \
            -H "Authorization: Bearer ${CF_API_TOKEN}" \
            -H "Content-Type: application/json" \
            --data '{"purge_everything":true}' \
            | tee /dev/stderr