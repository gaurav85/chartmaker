name: Build FAA tiles and publish to Cloudflare R2 (dev)

on:
  workflow_dispatch:

defaults:
  run:
    shell: bash

jobs:
  process-charts:
    runs-on: ubuntu-latest
    container:
      image: n129bz/chartmaker:latest

    strategy:
      fail-fast: false
      matrix:
        chart_type:
          - { id: vfr,      args: "area-all" }
          - { id: ifr_low,  args: "full-single=5" }
          - { id: ifr_high, args: "full-single=6" }

    env:
      WEBSERVERMODE: "false"
      # R2 is S3-compatible; configure AWS CLI to talk to R2
      AWS_ACCESS_KEY_ID:     ${{ secrets.R2_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
      AWS_DEFAULT_REGION:    auto
      AWS_S3_FORCE_PATH_STYLE: "true"
      AWS_ENDPOINT_URL_S3:  https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com
      R2_BUCKET:            ${{ secrets.R2_BUCKET }}
      R2_PUBLIC_HOST:       ${{ secrets.R2_PUBLIC_HOST }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install Node & jq in container
        run: |
          set -euxo pipefail
          if ! command -v node >/dev/null 2>&1; then
            if command -v apt-get >/dev/null 2>&1; then
              apt-get update
              apt-get install -y curl ca-certificates gnupg jq
              mkdir -p /etc/apt/keyrings
              curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg
              echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_18.x nodistro main" > /etc/apt/sources.list.d/nodesource.list
              apt-get update && apt-get install -y nodejs
            elif command -v apk >/dev/null 2>&1; then
              apk add --no-cache nodejs-current npm jq
            else
              echo "Unsupported base image"; exit 1
            fi
          else
            (apt-get update && apt-get install -y jq) || true
          fi
          node -v
          jq --version

      - name: Force CI settings (no web; keep intermediate tiles)
        working-directory: /chartmaker
        run: |
          set -euxo pipefail
          jq '.settings.webservermode=false
              | .settings.opendefaultbrowser=false
              | .settings.cleanprocessfolders=false' settings.json > s && mv s settings.json
          jq '.settings | {webservermode, opendefaultbrowser, cleanprocessfolders}' settings.json

      - name: Copy chartdates.json into container
        run: |
          set -euxo pipefail
          cp "$GITHUB_WORKSPACE/chartdates.json" /chartmaker/chartdates.json

      # ----- AWS CLI v2 (talks to R2 using env endpoint) -----
      - name: Install AWS CLI
        run: |
          set -euxo pipefail
          apt-get update
          apt-get install -y unzip curl
          curl -sSL "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o awscliv2.zip
          unzip -q awscliv2.zip
          ./aws/install --bin-dir /usr/local/bin --install-dir /usr/local/aws-cli || true
          aws --version

      # ----- Pick FAA date from chartdates.json (MM-DD-YYYY) -----
      - name: Select FAA chart date from chartdates.json
        id: pickdate
        working-directory: /chartmaker
        run: |
          set -euo pipefail
          mapfile -t RAW < <(jq -r '.ChartDates[]' chartdates.json)
          if [ "${#RAW[@]}" -eq 0 ]; then
            echo "No ChartDates[] entries found" >&2; exit 1
          fi

          DATES=()
          for d in "${RAW[@]}"; do
            if [[ "$d" =~ ^([0-1][0-9])-([0-3][0-9])-(20[0-9]{2})$ ]]; then
              mm="${BASH_REMATCH[1]}"; dd="${BASH_REMATCH[2]}"; yyyy="${BASH_REMATCH[3]}"
              iso="${yyyy}-${mm}-${dd}"
              if epoch=$(date -u -d "$iso" +%s 2>/dev/null); then
                DATES+=("$iso")
              fi
            fi
          done
          if [ "${#DATES[@]}" -eq 0 ]; then
            echo "No valid dates after normalization" >&2; exit 1
          fi

          IFS=$'\n' read -r -d '' -a SORTED < <(printf "%s\n" "${DATES[@]}" | sort && printf '\0')
          TODAY_EPOCH="$(date -u +%s)"
          PREV=""; NEXT=""

          for iso in "${SORTED[@]}"; do
            epoch=$(date -u -d "$iso" +%s)
            if [ "$epoch" -le "$TODAY_EPOCH" ]; then
              PREV="$iso"
            else
              if [ -z "$NEXT" ]; then NEXT="$iso"; fi
            fi
          done

          if [ -n "$PREV" ]; then TARGET="$PREV"; else TARGET="$NEXT"; fi
          if [ -z "${TARGET:-}" ]; then
            echo "Could not determine target date" >&2; exit 1
          fi
          echo "target_date=$TARGET" >> "$GITHUB_OUTPUT"
          echo "Selected FAA chart date: $TARGET (today=$(date -u +%Y-%m-%d))"

      # ----- Skip if tiles exist in R2 -----
      - name: Check R2 for existing tiles (skip if present)
        id: check_r2
        env:
          CHART_TYPE:  ${{ matrix.chart_type.id }}
          TARGET_DATE: ${{ steps.pickdate.outputs.target_date }}
        run: |
          set -euo pipefail
          PREFIX="tiles/${CHART_TYPE}/${TARGET_DATE}/"
          echo "Checking r2://${R2_BUCKET}/${PREFIX}"
          COUNT="$(aws s3api list-objects-v2 --bucket "${R2_BUCKET}" --prefix "${PREFIX}" --max-keys 1 --query 'KeyCount' --output text || echo 0)"
          if [ "${COUNT}" != "0" ]; then
            echo "exists=true" >> "$GITHUB_OUTPUT"
            echo "Tiles already present — skipping build/upload."
          else
            echo "exists=false" >> "$GITHUB_OUTPUT"
            echo "No tiles yet — will build and upload."
          fi

      # ----- IFR High: alias any h* to l* clipshapes -----
      - name: Fix IFR High clipshape filenames (create l* aliases for all h*)
        if: matrix.chart_type.id == 'ifr_high'
        working-directory: /chartmaker/clipshapes/enroute_high
        run: |
          set -euxo pipefail
          shopt -s nullglob
          for shp in enr_h*.shp; do
            base="${shp%.shp}"; num="${base#enr_h}"; dst="enr_l${num}"
            for ext in shp shx dbf prj; do
              if [ -f "${base}.${ext}" ] && [ ! -e "${dst}.${ext}" ]; then
                cp -f "${base}.${ext}" "${dst}.${ext}"
              fi
            done
          done
          ls -1 || true

      # ----- Build if needed -----
      - name: Build charts for ${{ matrix.chart_type.id }}
        if: steps.check_r2.outputs.exists != 'true'
        working-directory: /chartmaker
        env:
          WEBSERVERMODE: "false"
        run: |
          set -euxo pipefail
          node make "${{ matrix.chart_type.args }}"

      # ----- Find tile roots -----
      - name: Locate tile roots
        if: steps.check_r2.outputs.exists != 'true'
        id: tiles
        run: |
          set -euo pipefail
          ROOT="/chartmaker/workarea"
          test -d "$ROOT" || { echo "No workarea found"; exit 1; }
          mapfile -t TILE_ROOTS < <(find "$ROOT" -type d -maxdepth 3 -regex '.*/[0-9]+' -printf '%h\n' | sort -u)
          if [ ${#TILE_ROOTS[@]} -eq 0 ]; then
            echo "No tile folders detected in $ROOT" >&2; exit 1
          fi
          printf "%s\n" "${TILE_ROOTS[@]}" > /tmp/tile_roots.txt
          echo "tile_roots_file=/tmp/tile_roots.txt" >> "$GITHUB_OUTPUT"
          head -10 /tmp/tile_roots.txt || true

      # ----- Upload to R2 (S3 API) -----
      - name: Upload tiles to R2
        if: steps.check_r2.outputs.exists != 'true'
        env:
          TILE_ROOTS_FILE: ${{ steps.tiles.outputs.tile_roots_file }}
          CHART_TYPE:      ${{ matrix.chart_type.id }}
          TARGET_DATE:     ${{ steps.pickdate.outputs.target_date }}
        run: |
          set -euxo pipefail
          DEST="s3://${R2_BUCKET}/tiles/${CHART_TYPE}/${TARGET_DATE}/"
          echo "Destination: $DEST (via ${AWS_ENDPOINT_URL_S3})"
          while IFS= read -r ROOT; do
            echo "Syncing $ROOT -> $DEST"
            aws s3 sync "$ROOT/" "$DEST" --only-show-errors
          done < "$TILE_ROOTS_FILE"

          echo "${TARGET_DATE}" > "latest_${CHART_TYPE}.txt"
          aws s3 cp "latest_${CHART_TYPE}.txt" "s3://${R2_BUCKET}/latest_${CHART_TYPE}.txt" --only-show-errors --content-type text/plain

      # ----- Keep only newest two dates per type -----
      - name: Retain only last two dates in R2
        env:
          CHART_TYPE: ${{ matrix.chart_type.id }}
        run: |
          set -euo pipefail
          mapfile -t PREFS < <(
            aws s3api list-objects-v2 \
              --bucket "${R2_BUCKET}" \
              --prefix "tiles/${CHART_TYPE}/" \
              --delimiter '/' \
              --query 'CommonPrefixes[].Prefix' \
              --output text | tr '\t' '\n' | sed -E 's#^tiles/'"${CHART_TYPE}"'/([^/]+)/$#\1#' | sort
          )
          if [ ${#PREFS[@]} -le 2 ]; then
            echo "Nothing to prune (dates: ${PREFS[*]:-none})"; exit 0
          fi
          KEEP1="${PREFS[-1]}"; KEEP2="${PREFS[-2]}"
          echo "Keeping: $KEEP2, $KEEP1"
          for d in "${PREFS[@]}"; do
            if [ "$d" != "$KEEP1" ] && [ "$d" != "$KEEP2" ]; then
              echo "Pruning tiles/${CHART_TYPE}/${d}/"
              aws s3 rm "s3://${R2_BUCKET}/tiles/${CHART_TYPE}/${d}/" --recursive --only-show-errors
            fi
          done

      # ----- Purge Cloudflare (zone cache) -----
      - name: Purge Cloudflare cache
        env:
          CF_ZONE_ID:   ${{ secrets.CLOUDFLARE_ZONE_ID }}
          CF_API_EMAIL: ${{ secrets.CLOUDFLARE_API_EMAIL }}
          CF_API_KEY:   ${{ secrets.CLOUDFLARE_API_KEY }}
        run: |
          set -euxo pipefail
          curl -sS "https://api.cloudflare.com/client/v4/zones/${CF_ZONE_ID}/purge_cache" \
            -H 'Content-Type: application/json' \
            -H "X-Auth-Email: ${CF_API_EMAIL}" \
            -H "X-Auth-Key: ${CF_API_KEY}" \
            -d '{"purge_everything":true}' \
            -w "\nHTTP Status: %{http_code}\n"

      # ----- Report & cleanup -----
      - name: Create processing report
        if: always()
        env:
          TARGET_DATE: ${{ steps.pickdate.outputs.target_date }}
          CHART_TYPE:  ${{ matrix.chart_type.id }}
        run: |
          set -euo pipefail
          REPORT="$GITHUB_WORKSPACE/report_${CHART_TYPE}.md"
          {
            echo "# Chart Processing Report (${CHART_TYPE})"
            echo
            echo "**UTC Now:** $(date -u)  "
            echo "**FAA Chart Date:** ${TARGET_DATE}  "
            echo "**Chart Type:** ${CHART_TYPE}  "
            echo
            echo "## Disk Usage"
            echo '```'
            df -h
            echo '```'
          } > "$REPORT"

      - name: Upload report as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: processing-report-${{ matrix.chart_type.id }}-${{ steps.pickdate.outputs.target_date }}
          path: report_${{ matrix.chart_type.id }}.md
          retention-days: 30

      - name: Cleanup
        if: always()
        run: |
          set +e
          rm -rf /chartmaker/workarea/* /chartmaker/chartcache/* 2>/dev/null || true
          echo "Cleanup completed"

  notify:
    needs: process-charts
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Send notification
        run: |
          if [ "${{ needs.process-charts.result }}" = "success" ]; then
            echo "✅ All chart types processed and uploaded (or skipped if current)."
            echo "Origin: https://${{ secrets.R2_PUBLIC_HOST }}/tiles/<type>/<date>/{z}/{x}/{y}.webp"
          else
            echo "❌ One or more chart types failed."
            echo "See: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          fi