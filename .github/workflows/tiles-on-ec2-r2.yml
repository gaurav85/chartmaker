name: Build FAA tiles on ephemeral EC2 and publish to Cloudflare R2

on:
  workflow_dispatch:
  schedule:
    - cron: "0 7 * * 1" # daily 07:00 UTC

permissions:
  id-token: write
  contents: read
  actions: write

jobs:
  start-runner:
    name: Start EC2 runner
    runs-on: ubuntu-latest
    outputs:
      label: ${{ steps.start.outputs.label }}
      ec2-instance-id: ${{ steps.start.outputs.ec2-instance-id }}
    steps:
      - name: Assume AWS role (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Start EC2 self-hosted runner
        id: start
        uses: machulav/ec2-github-runner@v2.3.3
        with:
          mode: start
          github-token: ${{ secrets.GH_RUNNER_PAT }}
          ec2-image-id: ${{ secrets.EC2_AMI_ID }}
          ec2-instance-type: c7i.2xlarge
          subnet-id: ${{ secrets.EC2_SUBNET_ID }}
          security-group-id: ${{ secrets.EC2_SECURITY_GROUP_ID }}
          label: ec2-tiles-${{ github.run_id }}
          runner-home-dir: /home/ubuntu
          wait-for-runner-timeout: 600

  build-all:
    name: Build + upload tiles (VFR / IFR-low / IFR-high)
    needs: start-runner
    runs-on: ${{ fromJSON(format('["self-hosted","{0}"]', needs.start-runner.outputs.label)) }}
    env:
      # R2 endpoint + creds
      AWS_DEFAULT_REGION: auto
      AWS_ENDPOINT_URL_S3: https://${{ secrets.R2_ACCOUNT_ID }}.r2.cloudflarestorage.com
      R2_BUCKET: ${{ secrets.R2_BUCKET }}
      R2_PUBLIC_HOST: ${{ secrets.R2_PUBLIC_HOST }}
      R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
      R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}

      # Build image + lookahead (set directly to avoid expression in env)
      DEFAULT_IMAGE: n129bz/chartmaker:latest
      LOOKAHEAD_DAYS: "5"
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install AWS CLI + jq on runner
        shell: bash
        run: |
          set -euxo pipefail
          if ! command -v aws >/dev/null 2>&1; then
            curl -sSL https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip -o awscliv2.zip
            unzip -q awscliv2.zip
            sudo ./aws/install --bin-dir /usr/local/bin --install-dir /usr/local/aws-cli || true
          fi
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update
            sudo apt-get install -y jq
          fi
          aws --version
          jq --version

      - name: Stage chartdates.json
        shell: bash
        run: |
          set -euxo pipefail
          mkdir -p /mnt/common
          cp chartdates.json /mnt/common/chartdates.json

      - name: Decide TARGET_DATE from chartdates.json
        id: pickdate
        shell: bash
        run: |
          set -euo pipefail
          LOOKAHEAD="${LOOKAHEAD_DAYS:-5}"

          mapfile -t RAW < <(jq -r '.ChartDates[]' /mnt/common/chartdates.json)
          DATES=()
          for d in "${RAW[@]}"; do
            if [[ "$d" =~ ^([0-1][0-9])-([0-3][0-9])-(20[0-9]{2})$ ]]; then
              iso="${BASH_REMATCH[3]}-${BASH_REMATCH[1]}-${BASH_REMATCH[2]}"
              date -u -d "$iso" +%s >/dev/null 2>&1 && DATES+=("$iso")
            fi
          done
          IFS=$'\n' read -r -d '' -a SORTED < <(printf "%s\n" "${DATES[@]}" | sort && printf '\0')

          TODAY=$(date -u +%s); PREV=""; NEXT=""
          for iso in "${SORTED[@]}"; do
            e=$(date -u -d "$iso" +%s)
            if [ "$e" -le "$TODAY" ]; then PREV="$iso"; else if [ -z "$NEXT" ]; then NEXT="$iso"; fi; fi
          done

          if [ -n "$NEXT" ]; then
            ne=$(date -u -d "$NEXT" +%s)
            dd=$(( (ne - TODAY) / 86400 ))
            if [ "$dd" -le "$LOOKAHEAD" ] && [ "$dd" -ge 0 ]; then
              TARGET_DATE="$NEXT"
            else
              TARGET_DATE="${PREV:-$NEXT}"
            fi
          else
            TARGET_DATE="$PREV"
          fi

          [ -n "$TARGET_DATE" ] || { echo "::error::Could not determine TARGET_DATE"; exit 1; }
          echo "TARGET_DATE=$TARGET_DATE"
          echo "target_date=$TARGET_DATE" >> "$GITHUB_OUTPUT"

      - name: Build all three in parallel
        id: build
        shell: bash
        env:
          TARGET_DATE: ${{ steps.pickdate.outputs.target_date }}
        run: |
          set -euo pipefail

          BUCKET="${R2_BUCKET}"
          ENDPOINT="${AWS_ENDPOINT_URL_S3}"
          TARGET="${TARGET_DATE}"

          echo "TARGET_DATE=${TARGET}"

          s3_prefix_exists() {
            local prefix="$1"
            AWS_ACCESS_KEY_ID="${R2_ACCESS_KEY_ID}" \
            AWS_SECRET_ACCESS_KEY="${R2_SECRET_ACCESS_KEY}" \
            aws --endpoint-url "${ENDPOINT}" s3api list-objects-v2 \
              --bucket "${BUCKET}" --prefix "${prefix}" --max-keys 1 \
              --query 'KeyCount' --output text 2>/dev/null | grep -qE '^[1-9][0-9]*$'
          }

          cat >/mnt/common/build_inside.sh <<'INSC'
          #!/usr/bin/env bash
          set -euo pipefail
          echo "[inside] ARGS=${ARGS} CHART_DATE=${CHART_DATE:-unset}"

          if ! command -v jq >/dev/null 2>&1; then
            if command -v apt-get >/dev/null 2>&1; then
              apt-get update && DEBIAN_FRONTEND=noninteractive apt-get install -y jq curl gnupg
            elif command -v apk >/dev/null 2>&1; then
              apk add --no-cache jq curl
            elif command -v yum >/dev/null 2>&1; then
              yum install -y jq curl -y
            fi
          fi

          if ! command -v node >/dev/null 2>&1; then
            if command -v apt-get >/dev/null 2>&1; then
              curl -fsSL https://deb.nodesource.com/setup_20.x | bash - && \
              DEBIAN_FRONTEND=noninteractive apt-get install -y nodejs
            elif command -v apk >/dev/null 2>&1; then
              apk add --no-cache nodejs npm
            elif command -v yum >/dev/null 2>&1; then
              curl -fsSL https://rpm.nodesource.com/setup_20.x | bash - && yum install -y nodejs
            fi
          fi

          cd /chartmaker
          jq '.settings.webservermode=false
              | .settings.opendefaultbrowser=false
              | .settings.cleanprocessfolders=false' settings.json > s && mv s settings.json

          export CHART_DATE="${CHART_DATE:-}"
          echo "[inside] invoking: node make ${ARGS}"
          node make "${ARGS}"

          echo "[inside] roots after build:"
          find /chartmaker/workarea -type d -maxdepth 3 -regex '.*/[0-9]+' -printf '%h\n' | sort -u || true
          INSC
          chmod +x /mnt/common/build_inside.sh

          run_chart() {
            local TYPE="$1" ARGS="$2"
            local WD="/mnt/builds/${TYPE}"
            mkdir -p "${WD}"/{workarea,chartcache,staging,logs}

            local CNAME="tiles-${TYPE}-${GITHUB_RUN_ID}-${GITHUB_RUN_ATTEMPT}"
            docker rm -f "${CNAME}" >/dev/null 2>&1 || true

            docker run -d --name "${CNAME}" \
              --user root \
              -e WEBSERVERMODE=false \
              -e ARGS="${ARGS}" \
              -e CHART_DATE="${TARGET}" \
              -v "${WD}/workarea:/chartmaker/workarea" \
              -v "${WD}/chartcache:/chartmaker/chartcache" \
              -v /mnt/common/chartdates.json:/chartmaker/chartdates.json:ro \
              -v /mnt/common/build_inside.sh:/entry.sh:ro \
              "${DEFAULT_IMAGE}" \
              bash /entry.sh >/dev/null

            echo "${CNAME}"
          }

          PIDS=()

          VFR_PREFIX="tiles/vfr/${TARGET}/"
          IFRL_PREFIX="tiles/ifr_low/${TARGET}/"
          IFRH_PREFIX="tiles/ifr_high/${TARGET}/"

          if s3_prefix_exists "${VFR_PREFIX}"; then
            echo "Skip vfr: already exists in R2."
          else
            echo "Start vfr build…"
            PIDS+=( "$(run_chart vfr 'area-all')" )
          fi

          if s3_prefix_exists "${IFRL_PREFIX}"; then
            echo "Skip ifr_low: already exists in R2."
          else
            echo "Start ifr_low build…"
            PIDS+=( "$(run_chart ifr_low 'enroute-low')" )
          fi

          if s3_prefix_exists "${IFRH_PREFIX}"; then
            echo "Skip ifr_high: already exists in R2."
          else
            echo "Start ifr_high build…"
            PIDS+=( "$(run_chart ifr_high 'enroute-high')" )
          fi

          # Start where needed
          NAMES=()

          if s3_prefix_exists "${VFR_PREFIX}"; then
            echo "Skip vfr: already exists in R2."
          else
            echo "Start vfr build…"
            NAMES+=( "$(run_chart vfr 'area-all')" )
          fi

          if s3_prefix_exists "${IFRL_PREFIX}"; then
            echo "Skip ifr_low: already exists in R2."
          else
            echo "Start ifr_low build…"
            NAMES+=( "$(run_chart ifr_low 'enroute-low')" )
          fi

          if s3_prefix_exists "${IFRH_PREFIX}"; then
            echo "Skip ifr_high: already exists in R2."
          else
            echo "Start ifr_high build…"
            NAMES+=( "$(run_chart ifr_high 'enroute-high')" )
          fi

          # Wait for each container to finish and check exit code
          if [ "${#NAMES[@]}" -eq 0 ]; then
            echo "Nothing to build — all tile sets already present in R2 for ${TARGET}."
          else
            for cname in "${NAMES[@]}"; do
              echo "Waiting for container ${cname} …"
              code=$(docker wait "${cname}" || echo 1)
              echo "Container ${cname} exit code: ${code}"
              if [ "${code}" -ne 0 ]; then
                echo "::error::Build container ${cname} failed. Last logs:"
                docker logs --tail 200 "${cname}" || true
                exit 1
              fi
            done
          fi

          for T in vfr ifr_low ifr_high; do
            WD="/mnt/builds/${T}"
            if [ -d "${WD}/workarea" ]; then
              mapfile -t ROOTS < <(find "${WD}/workarea" -type d -maxdepth 3 -regex '.*/[0-9]+' -printf '%h\n' | sort -u)
              echo "${T} roots: ${#ROOTS[@]}"
              if [ "${#ROOTS[@]}" -eq 0 ]; then
                echo "::warning::No tile roots detected for ${T}; see ${WD}/logs/build.log"
              fi
            else
              echo "::notice::${T} has no workarea (likely skipped)."
            fi
          done

      - name: Upload to R2 + write latest_*.txt
        shell: bash
        env:
          TARGET_DATE: ${{ steps.pickdate.outputs.target_date }}
        run: |
          set -euo pipefail
          ENDPOINT="${AWS_ENDPOINT_URL_S3}"
          BUCKET="${R2_BUCKET}"
          DATE="${TARGET_DATE}"

          for TYPE in vfr ifr_low ifr_high; do
            WD="/mnt/builds/${TYPE}"
            [ -d "${WD}/workarea" ] || { echo "Skip ${TYPE}: no workarea"; continue; }
            mapfile -t ROOTS < <(find "${WD}/workarea" -type d -maxdepth 3 -regex '.*/[0-9]+' -printf '%h\n' | sort -u)
            if [ "${#ROOTS[@]}" -eq 0 ]; then
              echo "Skip ${TYPE}: no tile roots."
              continue
            fi

            DEST="s3://${BUCKET}/tiles/${TYPE}/${DATE}/"
            echo "Uploading ${TYPE} -> ${DEST}"
            for R in "${ROOTS[@]}"; do
              AWS_ACCESS_KEY_ID="${R2_ACCESS_KEY_ID}" \
              AWS_SECRET_ACCESS_KEY="${R2_SECRET_ACCESS_KEY}" \
              aws --endpoint-url "${ENDPOINT}" s3 sync "$R/" "$DEST" --only-show-errors
            done

            echo "${DATE}" > "/mnt/common/latest_${TYPE}.txt"
            AWS_ACCESS_KEY_ID="${R2_ACCESS_KEY_ID}" \
            AWS_SECRET_ACCESS_KEY="${R2_SECRET_ACCESS_KEY}" \
            aws --endpoint-url "${ENDPOINT}" s3 cp "/mnt/common/latest_${TYPE}.txt" "s3://${BUCKET}/latest_${TYPE}.txt" \
              --only-show-errors --content-type text/plain
          done

      - name: Keep only newest two dates per type
        shell: bash
        run: |
          set -euo pipefail
          ENDPOINT="${AWS_ENDPOINT_URL_S3}"
          BUCKET="${R2_BUCKET}"

          for TYPE in vfr ifr_low ifr_high; do
            mapfile -t PREFS < <(
              AWS_ACCESS_KEY_ID="${R2_ACCESS_KEY_ID}" AWS_SECRET_ACCESS_KEY="${R2_SECRET_ACCESS_KEY}" \
              aws --endpoint-url "${ENDPOINT}" s3api list-objects-v2 \
                --bucket "${BUCKET}" --prefix "tiles/${TYPE}/" --delimiter '/' \
                --query 'CommonPrefixes[].Prefix' --output text \
              | tr '\t' '\n' | sed -E 's#^tiles/'"${TYPE}"'/([^/]+)/$#\1#' | sort
            )
            if [ ${#PREFS[@]} -gt 2 ]; then
              KEEP1="${PREFS[-1]}"; KEEP2="${PREFS[-2]}"
              for d in "${PREFS[@]}"; do
                if [ "$d" != "$KEEP1" ] && [ "$d" != "$KEEP2" ]; then
                  echo "Pruning tiles/${TYPE}/${d}/"
                  AWS_ACCESS_KEY_ID="${R2_ACCESS_KEY_ID}" AWS_SECRET_ACCESS_KEY="${R2_SECRET_ACCESS_KEY}" \
                  aws --endpoint-url "${ENDPOINT}" s3 rm "s3://${BUCKET}/tiles/${TYPE}/${d}/" --recursive --only-show-errors
                fi
              done
            fi
          done

      - name: (Optional) Purge Cloudflare cache
        if: ${{ always() }}
        env:
          CF_ZONE:  ${{ secrets.CLOUDFLARE_ZONE_ID }}
          CF_EMAIL: ${{ secrets.CLOUDFLARE_API_EMAIL }}
          CF_KEY:   ${{ secrets.CLOUDFLARE_API_KEY }}
        run: |
          set -euxo pipefail
          if [ -z "${CF_ZONE}" ]; then
            echo "Cloudflare purge skipped: CF_ZONE not set."
            exit 0
          fi
          curl -sS "https://api.cloudflare.com/client/v4/zones/${CF_ZONE}/purge_cache" \
            -H 'Content-Type: application/json' \
            -H "X-Auth-Email: ${CF_EMAIL}" \
            -H "X-Auth-Key: ${CF_KEY}" \
            -d '{"purge_everything":true}' \
            -w "\nHTTP Status: %{http_code}\n"

      - name: Cleanup disks
        if: always()
        shell: bash
        run: |
          set +e
          rm -rf /mnt/builds/*/workarea/* /mnt/builds/*/chartcache/* 2>/dev/null || true
          df -h

  stop-runner:
    name: Stop EC2 runner
    if: always()
    needs: [start-runner, build-all]
    runs-on: ubuntu-latest
    steps:
      - name: Assume AWS role (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Stop EC2 self-hosted runner
        uses: machulav/ec2-github-runner@v2.3.3
        with:
          mode: stop
          github-token: ${{ secrets.GH_RUNNER_PAT }}
          label: ${{ needs.start-runner.outputs.label }}
          ec2-instance-id: ${{ needs.start-runner.outputs.ec2-instance-id }}

  notify:
    needs: [stop-runner]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Send notification
        run: |
          if [ "${{ needs.stop-runner.result }}" == "success" ]; then
            echo "✅ Charts processed and uploaded successfully"
            echo "Access at: https://charts.leonis85.com/"
          else
            echo "❌ Chart processing failed"
            echo "Check logs at: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          fi